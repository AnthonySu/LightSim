{
  "experiment": "rl_crossval_grid",
  "scenario": "grid-4x4-v0",
  "num_agents": 16,
  "total_timesteps": 50000,
  "n_seeds": 3,
  "variants": [
    "DQN",
    "PPO"
  ],
  "results": [
    {
      "simulator": "LightSim",
      "variant": "DQN",
      "seed": 0,
      "train_time": 46.9,
      "eval_reward_mean": -167887.89,
      "eval_reward_std": 0.0
    },
    {
      "simulator": "LightSim",
      "variant": "DQN",
      "seed": 1,
      "train_time": 44.6,
      "eval_reward_mean": -122989.83,
      "eval_reward_std": 0.0
    },
    {
      "simulator": "LightSim",
      "variant": "DQN",
      "seed": 2,
      "train_time": 45.3,
      "eval_reward_mean": -180586.74,
      "eval_reward_std": 0.0
    },
    {
      "simulator": "LightSim",
      "variant": "PPO",
      "seed": 0,
      "train_time": 96.0,
      "eval_reward_mean": -94733.61,
      "eval_reward_std": 0.0
    },
    {
      "simulator": "LightSim",
      "variant": "PPO",
      "seed": 1,
      "train_time": 95.2,
      "eval_reward_mean": -112865.97,
      "eval_reward_std": 0.0
    },
    {
      "simulator": "LightSim",
      "variant": "PPO",
      "seed": 2,
      "train_time": 91.8,
      "eval_reward_mean": -94733.54,
      "eval_reward_std": 0.0
    }
  ]
}